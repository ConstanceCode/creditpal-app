sem analyze_article = "Analyze an article for credibility and quality. Consider: source reputation and historical credibility score, writing quality and journalistic standards, fact-checking and citation of sources, sensationalism vs factual reporting, transparency about authors and funding. Return dictionary with: credibility_score (0-100), confidence (0-1), red_flags (list of strings), positive_signals (list of strings), reasoning (string explanation).";

sem detect_bias = "Detect political or ideological bias in article content. Analyze: word choice and framing, selection of facts presented, tone and emotional language, balance of perspectives, attribution and sourcing patterns. Return dictionary with: bias_score (float from -100 to +100 where negative is left and positive is right), bias_category (string: far-left, left, center-left, center, center-right, right, far-right), confidence (0-1), indicators (list of strings), explanation (string).";

sem detect_polarization = "Measure how polarizing or inflammatory the article's language is. Look for: emotionally charged language, us vs them framing, absolute statements and generalizations, dehumanizing language, conspiracy theory indicators, outrage-inducing framing. Return float (0-100) where 0-25 is neutral balanced reporting, 26-50 is some emotional language, 51-75 is clearly polarizing, and 76-100 is highly inflammatory.";

sem extract_claims = "Extract factual claims from article content. Focus on: verifiable statements of fact, statistical claims, quotes attributed to sources, causal relationships stated as fact, predictions presented as likely. Exclude: opinions clearly marked as such, hypotheticals, rhetorical questions. Return list of claim strings, for example: 'The GDP grew by 3.2% in Q4 2024', 'Senator X voted against the bill', 'Studies show that Y causes Z'.";

sem verify_claims = "Cross-check claims across multiple articles to verify accuracy. For each claim: find similar claims in other articles, check if reputable sources confirm or deny it, look for contradicting information, assess consensus among sources. Return dictionary mapping claims to verification results with keys: status (verified, disputed, unverified, false), confidence (0-1), supporting_sources (int), contradicting_sources (int), explanation (string).";

sem summarize_article = "Generate a concise neutral summary of the article. Requirements: maximum 3-4 sentences (60-80 words), focus on key facts and main points, maintain neutral tone and remove bias, include who what when where why, no opinions or interpretations. Return string summary.";

sem extract_entities = "Extract key entities and topics from the article. Identify: people (politicians, experts, public figures), organizations (companies, governments, NGOs), locations (countries, cities, regions), events (elections, disasters, meetings), topics and themes (healthcare, economy, technology). Return dictionary with keys: people (list of strings), organizations (list of strings), locations (list of strings), events (list of strings), topics (list of strings).";

sem calculate_relevance = "Calculate how relevant an article is to a user's interests. Consider: direct keyword matches with user interests, topic overlap and semantic similarity, entities that match user's reading history, novelty vs redundancy with already-read articles. Return float (0-1) where 0.0-0.3 is low relevance, 0.3-0.6 is moderate relevance, and 0.6-1.0 is high relevance.";

sem recommend_articles = "Generate personalized article recommendations for a user. Algorithm: calculate relevance scores for each article, weight by credibility scores, boost articles from diverse sources, penalize articles too similar to recently read, include some surprise articles outside comfort zone. Ranking factors: relevance to interests 40%, credibility score 30%, diversity (viewpoint and source) 20%, novelty and freshness 10%. Return list of Article objects sorted by recommendation score with top 10-15 articles.";